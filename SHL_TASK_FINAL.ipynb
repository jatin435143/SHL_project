{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNlkLv7mr99_",
    "outputId": "9d3094b4-f218-4a04-da4c-2b747238cb1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "SuGITp_Bs0Xp",
    "outputId": "9f8dcb11-1933-4546-9609-06186180120b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-f7c21cab-534f-41ed-ab2f-3024f74f246d\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-f7c21cab-534f-41ed-ab2f-3024f74f246d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"jatinsharma1703\",\"key\":\"a36e1b6fda7e387dda59825922d8ec1f\"}'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOmpviXMs0UZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "os.replace('kaggle.json', os.path.expanduser('~/.kaggle/kaggle.json'))\n",
    "\n",
    "os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuImOv3MJf4S"
   },
   "source": [
    "### Downloading dataset from kaggle using API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FopLkOzss0SP",
    "outputId": "07081e16-8d42-42be-925b-af9f0b9d22bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shl-hiring-assessment.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c shl-hiring-assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oihkBv0s0P5"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('shl-hiring-assessment.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('shl-hiring-assessment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyqwnKKMJnel"
   },
   "source": [
    "### Importing the Dataset from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFCKUOg8s0NB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"shl-hiring-assessment/Dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"shl-hiring-assessment/Dataset/test.csv\")\n",
    "submission_df = pd.read_csv(\"shl-hiring-assessment/Dataset/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO0jilgRs0Kl"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai-whisper\n",
    "import whisper\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShE-5P28s0H0"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_mrLVoXs0FP"
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "AUDIO_PATH_TRAIN = \"shl-hiring-assessment/Dataset/audios/train\"\n",
    "AUDIO_PATH_TEST = \"shl-hiring-assessment/Dataset/audios/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_r_9cSEsz5s"
   },
   "outputs": [],
   "source": [
    "transcripts_train = []\n",
    "transcripts_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXURELJ2JwNB"
   },
   "source": [
    "### Generating transcripts of the audio files using whisper base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOs7bcHFO3I3"
   },
   "outputs": [],
   "source": [
    "def get_transcripts(dataset,transcripts,AUDIO_PATH):\n",
    "  for fname in tqdm(dataset['filename']):\n",
    "    file_path = os.path.join(AUDIO_PATH, fname)\n",
    "    try:\n",
    "        result = model.transcribe(file_path)\n",
    "        transcripts.append(result['text'].strip())\n",
    "    except Exception as e:\n",
    "        transcripts.append(\"[ERROR]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cMs05iDPTs6",
    "outputId": "b2c4942d-78db-4b14-d36a-292f21910db2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 444/444 [37:29<00:00,  5.07s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204/204 [11:40<00:00,  3.44s/it]\n"
     ]
    }
   ],
   "source": [
    "get_transcripts(train_df,transcripts_train,AUDIO_PATH_TRAIN)\n",
    "get_transcripts(test_df,transcripts_test,AUDIO_PATH_TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-bJ38LRPlcI"
   },
   "outputs": [],
   "source": [
    "train_df['transcript'] = transcripts_train\n",
    "test_df['transcript'] = transcripts_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzOyc0yNJ7UG"
   },
   "source": [
    "### Saving the files containing transcript if needed to import in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLc75xjacLtJ"
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('merged_train_with_transcripts.csv', index=False)\n",
    "test_df.to_csv('merged_test_with_transcripts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lW0vNkEmKDO7"
   },
   "source": [
    "### Removing null values of the transcript ( less in number (1,2 out of total) so removed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsMaONJje8L2"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df['transcript'].isnull()]\n",
    "test_df = test_df[~test_df['transcript'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6BR-rwoKVS3"
   },
   "source": [
    "## Using Bert model to encode the transcriptions as it captures sequential meaning bidirectionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "05e92a3e4112483885164bfda021279e",
      "2b216bf27c4645ba98502abb5ca1e93a",
      "1f07913d5e8841f8a934ce63414f5c80",
      "4aa3c453851b400e8a5606c39cf81951",
      "6bc946d0924942109c1942916bd5df97",
      "21d18f9ab3fa4ae1a55b62b4896a835b",
      "6628d2cebcfa4a9191d2043b0ce7f665",
      "42e3eeab1beb450e8678c594420d12bb",
      "0d6ac13d003843e0843ae9efde782cf5",
      "35c637227fc84f52a615a4913188de02",
      "bdaae6b2d4c74899bb0b169bb8d97d9e",
      "cb1e7701ce10463196ee225e84faf45e",
      "43b21dca9f83412c916d4fb1d694622e",
      "82d983af68f8478a996136857be66557",
      "ab9b396135dc4d89af889a149a916be2",
      "e541ce55f3264712b2568792945c72fa",
      "718c4cd06e1a4ef9b7f9ff5da9d26a2c",
      "4b1ebc8047dc447dae1be8bc6c18f5d6",
      "ee4ce8a058ac491898794c402314bc2e",
      "c0b8dea163074fefa2597f867c751009",
      "f3e853d488aa4aa1ae330d188fce4258",
      "97d2499f1a0f42568062d9c363e450f9",
      "11f5771174aa4119ac61b38034519e82",
      "8b12fb042de94f4687691ac55fd7135d",
      "36ac3eea882a42f9a0372fe64d667e1b",
      "fa0c102d42714d8281244042d3a41b32",
      "19b6efd8e8954ae2b913e57b882a676d",
      "f852b415e8fc477a89012a3f687e0faf",
      "24bc2baf322f469ca18de2bb93a4b9f3",
      "e17e7e8639f7451eb0d72aba5cd106e2",
      "208a754d89ae46b6a1aedf92191db1a7",
      "c777cf3c8abe4ca79c4c107c51fd0a9b",
      "2b171c5e8c7844c4a8d8d7887e7b48f5",
      "3e8fd47fa0a84e1488ad63dd296bd08e",
      "a47df0a323f846348410530a440964e9",
      "0e68147a676a446587acff8107e55990",
      "df1430f0179d4bbf9b17b95ab95702c4",
      "00545ff59332419cb07f67100c1dc00f",
      "51a43c45e89e40a098b87b1ee06dcb60",
      "e003e3a4119d467c97040dc5120c2b22",
      "28e7796b6a94471f960c1a3e35538c0e",
      "07527bf352cd4e0f986c4db5e843e5c9",
      "10536d24f03e4a6eb6d743f4137a2693",
      "88598a95029b44c68aefe57f3e39a1cd",
      "2bcdc7c87e5e4115a1b59e07eac6915a",
      "3fa4ec7daf3042e49ed38a362e5a4acc",
      "62a4e4851bbd42ef9a42bdbb91d27585",
      "1881ced51bf146bd992408e282296408",
      "14b121ec77ac4e8299d90251996457ed",
      "21605d9876314dc7b20f7560de844106",
      "0976b4b384244d82a11a87f223367935",
      "a517b004f7d6473dbeaac5b71855c813",
      "966dc1a3fdcb4b5cb1099c91f07910b9",
      "61a7233468084d8fb4e35899e5e402e9",
      "166d4a07e1684cc2afdeea8be07ac517",
      "49bd0a2c2802439d9688234ceb12898d",
      "a2703db4b51c40558643934c57ce67a0",
      "477ec873a85c4484b7287def03aead43",
      "a8f0f0e6d8314b0fb8b95f5158fd79dd",
      "1202b73718c04546afbbdc22e33e7d0b",
      "3f686fcf2a05482ca0e827cde78691dd",
      "0a891fbfc1e7409ab24a3d9b4e54c139",
      "2e89933cb95245378b8f4478cd739fd8",
      "ef676158e9d44cafbf086ed12699b32c",
      "f5481e50913d4562a60cf5edd08d657b",
      "c9af73f645bf4b919eb6a79d3e729f05",
      "bcd9d9b89d2e4a258e13e82c6abe95a1",
      "8ce1b52d22c64a94b3b2fb3545d2211b",
      "bb6fb1872de14f708773eed398fc3f6f",
      "4e6cbf2a31944a9b9339233127aa729d",
      "605473a705da4790ba9e3d49a45b1bd9",
      "dc61628057f741069fbeb95274507af8",
      "811bbfa24fb64a248a2b004e8e0884f1",
      "a472f3869f68439d9ae477faf66080d6",
      "0e75db5772fa481a917f49a78729650d",
      "4c7e503bde2b4f459384ee394e1bc2da",
      "ed06078c1ef6403cb3a8e965ee78b1f8",
      "9e62e8a565f4496da973a5799ab391f7",
      "8c9e0e685d0e4e98ad21b44ace0143ad",
      "a068c172d118497286dac06243622418",
      "85d0f33db7404e2585b142c97332f858",
      "81c1f5cfcb754813a862cd0305b500dd",
      "a89e21c8042c4aa69fc3e7a7d61cf91c",
      "5d94ecc646eb40e88fb972aa541fc99d",
      "1c83aef55b9145ddbc4c084614e1b25e",
      "dea7bfb838b544da9779e8fa8e1d0207",
      "88b51909fba446ad81c3e3f4d43af266",
      "c8dc47975e4e42c8b07a1a441ce2e263",
      "d58e438e3aa14cd0b638426ce733c45a",
      "cf211f176c0b4c18be9b3443ed1843b5",
      "bd9188c6c1eb48089572eb575ccc0f46",
      "69615621de0343468d585039760d8595",
      "ee708010b4084f91905d9c9d52e6daad",
      "5780432373274d49825bf76a476151a9",
      "91a2b65bae3f458fbf14e35fea96ab93",
      "43079befadd94349be00ff13b759ccd3",
      "f16713a314d241079e94cf8e5cced098",
      "b1c8a67ddd4346079ee0af8ef10160ae",
      "9e21c31da368441094b2b74af2a8f43c",
      "e3b0d15dad514078974aee344cd3692e",
      "6138e6ba49ab41ed8ed8b4645cf3c6bd",
      "9f04c6df650c4fd89786d31a42f5c15f",
      "b69e67bba66d4630828e976ea2786403",
      "9c7da883aab848e199fcd3ef4c3de764",
      "363416a998cb4b38857ffce95e3c94f2",
      "608305cc308446cda2a3b17ca4327bfa",
      "5223696a1912496b818a73755b0ad0a1",
      "210bb35d261f44958f9fa06892b3a099",
      "ff29d7c72b7f4d38971c7c9ef173f6cb",
      "eb62b5b86a1240719b578fb3bc125d48",
      "4f5491054dae4209ad3c1877c6ffbbbe",
      "25467c65c8d944439b855740af7240f7",
      "52007bdb7be6493dbf7f27ebeedeaf00",
      "44686d4aafda4656b1d6ea39bf8c1aac",
      "ff484ffc01fd4370acdb17ef5fc3f7d9",
      "f52e2e37845b47a2b018f8eb9060d455",
      "ff027a1011774f7ca4bb7ada23e28daf",
      "3cc3179e17df4441a615f055b981720f",
      "003ad19ab6b7480d8b8abd6e017ad24f",
      "825edf4ea2da44a699d89ceee1e64b21",
      "2de0270e3bcc4d8fad463c60ecab1112",
      "c5e4b5adb667485694f5e4234082b8a1",
      "2942f6aba1fe4c07b7ed26e958f4aa75",
      "34e400c3bad34346b354c8a2e6c926eb",
      "3a8feede161d45e489da20031a60608e",
      "b56f944b550c45a08edbf164b1d821dd",
      "471c4117792f4125b0e521c6a2e609b5",
      "1d4cddc62f92413e89f71cd567bb3efb",
      "dc8dc7a32d624e7aac8d6be842d8abe4",
      "6f22bc9b8a0444fabb1df244102ec858",
      "4b96d9c44fa842058c4ac59cc5220ef3",
      "bea3dc2e247d428e9e0f2a231da18940",
      "e904a14ab8c94ef5a88a4c0cf117f803",
      "c0637d65c0fc4d9dbfe2b5affe420bbc",
      "7d43a8c6da344f7ab57ac9a69d97a10a",
      "79a2d6c5941943e7a00b671d3fa51040",
      "6208916ce2d04ebd9aadd1b76968d6be",
      "486bf080ee8242779b226235b9455f4b",
      "a94ab566ff634153b1b8555093bc57f3",
      "286b254197c14075b5d29b5bde049918",
      "3098b9ab44c7407ba5437f2fafbf4904",
      "96a580b7c18a4674a2ecdd3663b04df2",
      "362afdabf3ec4fefad3f9998c675128b"
     ]
    },
    "id": "NA-W2ykNo7kF",
    "outputId": "ef69d119-b050-4d9d-dd46-8e944cc06e98"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e92a3e4112483885164bfda021279e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1e7701ce10463196ee225e84faf45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f5771174aa4119ac61b38034519e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8fd47fa0a84e1488ad63dd296bd08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcdc7c87e5e4115a1b59e07eac6915a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bd0a2c2802439d9688234ceb12898d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd9d9b89d2e4a258e13e82c6abe95a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e62e8a565f4496da973a5799ab391f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58e438e3aa14cd0b638426ce733c45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b0d15dad514078974aee344cd3692e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5491054dae4209ad3c1877c6ffbbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e4b5adb667485694f5e4234082b8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e904a14ab8c94ef5a88a4c0cf117f803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 113912\n",
      "[LightGBM] [Info] Number of data points in the train set: 443, number of used features: 771\n",
      "[LightGBM] [Info] Start training from score 3.969526\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "X_train_text = model.encode(train_df['transcript'].tolist(), show_progress_bar=True)\n",
    "X_test_text = model.encode(test_df['transcript'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xKILmcOLqqI"
   },
   "source": [
    "### ðŸ’¡ POS Feature Extraction and Integration for Text Classification\n",
    "### This section enhances text-based features by extracting linguistic patterns from transcripts.\n",
    "### Specifically, we:\n",
    "### - Use spaCy to count key Part-of-Speech (POS) tags (NOUN, VERB, ADJ, ADV, PROPN), which capture grammatical structure.\n",
    "### - Represent each transcript as a fixed-length vector of POS tag counts.\n",
    "### - Scale these features for consistency and better performance in machine learning models.\n",
    "### - Combine the scaled POS features with precomputed text-based features (e.g., embeddings or TF-IDF)\n",
    "###   to form a richer, more informative feature set for model training and prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeHq5rmP9qC4",
    "outputId": "338f0e2a-eb39-4806-9abb-dd39f0dfa694"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 443/443 [00:15<00:00, 28.06it/s]\n",
      "<ipython-input-140-ae09d080f359>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['pos_features'] = train_df['transcript'].progress_apply(extract_pos_features)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204/204 [00:06<00:00, 33.46it/s]\n",
      "<ipython-input-140-ae09d080f359>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['pos_features'] = train_df['pos_features'].apply(lambda x: x + [0]*(max_len - len(x)))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from spacy.symbols import NOUN, VERB, ADJ, ADV, PROPN\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "POS_TAGS = [NOUN, VERB, ADJ, ADV, PROPN]\n",
    "\n",
    "def extract_pos_features(text):\n",
    "    doc = nlp(text)\n",
    "    pos_counts = doc.count_by(spacy.attrs.POS)\n",
    "    return [pos_counts.get(tag, 0) for tag in POS_TAGS]\n",
    "\n",
    "tqdm.pandas()\n",
    "train_df['pos_features'] = train_df['transcript'].progress_apply(extract_pos_features)\n",
    "test_df['pos_features'] = test_df['transcript'].progress_apply(extract_pos_features)\n",
    "\n",
    "max_len = max(len(x) for x in train_df['pos_features'])\n",
    "train_df['pos_features'] = train_df['pos_features'].apply(lambda x: x + [0]*(max_len - len(x)))\n",
    "test_df['pos_features'] = test_df['pos_features'].apply(lambda x: x + [0]*(max_len - len(x)))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_pos_scaled = scaler.fit_transform(np.vstack(train_df['pos_features']))\n",
    "test_pos_scaled = scaler.transform(np.vstack(test_df['pos_features']))\n",
    "\n",
    "X_train_combined = np.hstack([X_train_text, train_pos_scaled])\n",
    "X_test_combined = np.hstack([X_test_text, test_pos_scaled])\n",
    "y_train = train_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWXPskXoK_Jh"
   },
   "source": [
    "### Experimented and got that these parameters work best for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lffhf2EDBygN"
   },
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.02,\n",
    "    objective='reg:squarederror',\n",
    "    booster='gbtree',\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    max_depth=4,\n",
    "    gamma=0,\n",
    ")\n",
    "\n",
    "reg.fit(X_train_combined, y_train)\n",
    "\n",
    "y_test_pred = reg.predict(X_test_combined)\n",
    "\n",
    "valid_scores = np.array([1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0])\n",
    "\n",
    "def round_to_closest_score(predictions, valid_scores):\n",
    "    idx = np.argmin(np.abs(valid_scores[:, None] - predictions), axis=0)\n",
    "    return valid_scores[idx]\n",
    "\n",
    "y_test_pred_rounded = round_to_closest_score(y_test_pred, valid_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItEoBy65LIk9"
   },
   "source": [
    "### uio.csv is same sample_submission.csv file but just given a nick name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1hmNgkRio3I"
   },
   "outputs": [],
   "source": [
    "sample=pd.read_csv('uio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_C9BS_hPio0e"
   },
   "outputs": [],
   "source": [
    "sample['label']=y_test_pred_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QGi49L1ioxE"
   },
   "outputs": [],
   "source": [
    "sample.to_csv('uio.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Gcf44e0z-G0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
